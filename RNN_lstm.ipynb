{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN_lstm.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/basawanayya/deep-learning/blob/master/RNN_lstm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQn7eDoqHzK4",
        "colab_type": "code",
        "outputId": "94f59d9c-79e0-41df-b518-acca65a04d85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        }
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11G5cgMCIeo7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x=[]\n",
        "for i in range(100):\n",
        "  x.append([[i+j] for j in range(5)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-R1msVMA45c",
        "colab_type": "code",
        "outputId": "01daae55-88eb-4d1c-f0b1-b2da60d3a2ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "x[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[[0], [1], [2], [3], [4]],\n",
              " [[1], [2], [3], [4], [5]],\n",
              " [[2], [3], [4], [5], [6]],\n",
              " [[3], [4], [5], [6], [7]],\n",
              " [[4], [5], [6], [7], [8]],\n",
              " [[5], [6], [7], [8], [9]],\n",
              " [[6], [7], [8], [9], [10]],\n",
              " [[7], [8], [9], [10], [11]],\n",
              " [[8], [9], [10], [11], [12]],\n",
              " [[9], [10], [11], [12], [13]]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwi0yd7PBC6a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " y = []\n",
        " for i in range(100):\n",
        "   y.append(i+5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_L1x2y3qBKmm",
        "colab_type": "code",
        "outputId": "0ae258bd-45eb-4896-9069-f031ade4d570",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[5, 6, 7, 8, 9, 10, 11, 12, 13, 14]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRSmod09BMO-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x, y = np.array(x), np.array(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rV7eM6enBYFq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x, y = x/100, y/100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3xPHkODBkRX",
        "colab_type": "code",
        "outputId": "8b37a557-89ae-4322-973a-fb43db05370c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x.shape, y.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((100, 5, 1), (100,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2MasUl_BoKS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x , y, test_size = .2, random_state = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRwGQibWCGBT",
        "colab_type": "code",
        "outputId": "b5a9aba2-35d3-433e-a4e5-efdd70c5fb01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "                                    tf.keras.layers.LSTM(1, batch_input_shape = (None, 5, 1), return_sequences= True),\n",
        "                                      tf.keras.layers.LSTM(5, return_sequences= True),\n",
        "                                      tf.keras.layers.LSTM(5,  return_sequences= True),\n",
        "                                      tf.keras.layers.LSTM(5,  return_sequences= True),\n",
        "                                      tf.keras.layers.LSTM(1, return_sequences = False)\n",
        "                                  \n",
        "\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IbMAHPRC5Yy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss = 'mse',\n",
        "              optimizer = 'adam',\n",
        "              metrics = ['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QwozpcpDMea",
        "colab_type": "code",
        "outputId": "25d1fcdc-fcf9-4bbf-f785-bbd2fb585ad1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 5, 1)              12        \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 5, 5)              140       \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 5, 5)              220       \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 5, 5)              220       \n",
            "_________________________________________________________________\n",
            "lstm_4 (LSTM)                (None, 1)                 28        \n",
            "=================================================================\n",
            "Total params: 620\n",
            "Trainable params: 620\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DApWMwkmDPlJ",
        "colab_type": "code",
        "outputId": "ad6cd4dc-023e-491d-fc32-d045a408bc87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit(x_train, y_train, epochs=400, validation_data=(x_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 80 samples, validate on 20 samples\n",
            "Epoch 1/400\n",
            "80/80 [==============================] - 0s 995us/sample - loss: 0.0826 - acc: 0.0125 - val_loss: 0.0654 - val_acc: 0.0000e+00\n",
            "Epoch 2/400\n",
            "80/80 [==============================] - 0s 810us/sample - loss: 0.0823 - acc: 0.0125 - val_loss: 0.0651 - val_acc: 0.0000e+00\n",
            "Epoch 3/400\n",
            "80/80 [==============================] - 0s 763us/sample - loss: 0.0821 - acc: 0.0125 - val_loss: 0.0649 - val_acc: 0.0000e+00\n",
            "Epoch 4/400\n",
            "80/80 [==============================] - 0s 768us/sample - loss: 0.0820 - acc: 0.0125 - val_loss: 0.0645 - val_acc: 0.0000e+00\n",
            "Epoch 5/400\n",
            "80/80 [==============================] - 0s 754us/sample - loss: 0.0817 - acc: 0.0125 - val_loss: 0.0643 - val_acc: 0.0000e+00\n",
            "Epoch 6/400\n",
            "80/80 [==============================] - 0s 807us/sample - loss: 0.0815 - acc: 0.0125 - val_loss: 0.0640 - val_acc: 0.0000e+00\n",
            "Epoch 7/400\n",
            "80/80 [==============================] - 0s 771us/sample - loss: 0.0813 - acc: 0.0125 - val_loss: 0.0637 - val_acc: 0.0000e+00\n",
            "Epoch 8/400\n",
            "80/80 [==============================] - 0s 781us/sample - loss: 0.0810 - acc: 0.0125 - val_loss: 0.0635 - val_acc: 0.0000e+00\n",
            "Epoch 9/400\n",
            "80/80 [==============================] - 0s 729us/sample - loss: 0.0807 - acc: 0.0125 - val_loss: 0.0632 - val_acc: 0.0000e+00\n",
            "Epoch 10/400\n",
            "80/80 [==============================] - 0s 898us/sample - loss: 0.0804 - acc: 0.0125 - val_loss: 0.0629 - val_acc: 0.0000e+00\n",
            "Epoch 11/400\n",
            "80/80 [==============================] - 0s 769us/sample - loss: 0.0801 - acc: 0.0125 - val_loss: 0.0626 - val_acc: 0.0000e+00\n",
            "Epoch 12/400\n",
            "80/80 [==============================] - 0s 823us/sample - loss: 0.0798 - acc: 0.0125 - val_loss: 0.0623 - val_acc: 0.0000e+00\n",
            "Epoch 13/400\n",
            "80/80 [==============================] - 0s 768us/sample - loss: 0.0794 - acc: 0.0125 - val_loss: 0.0618 - val_acc: 0.0000e+00\n",
            "Epoch 14/400\n",
            "80/80 [==============================] - 0s 820us/sample - loss: 0.0790 - acc: 0.0125 - val_loss: 0.0615 - val_acc: 0.0000e+00\n",
            "Epoch 15/400\n",
            "80/80 [==============================] - 0s 993us/sample - loss: 0.0786 - acc: 0.0125 - val_loss: 0.0611 - val_acc: 0.0000e+00\n",
            "Epoch 16/400\n",
            "80/80 [==============================] - 0s 835us/sample - loss: 0.0781 - acc: 0.0125 - val_loss: 0.0607 - val_acc: 0.0000e+00\n",
            "Epoch 17/400\n",
            "80/80 [==============================] - 0s 789us/sample - loss: 0.0777 - acc: 0.0125 - val_loss: 0.0602 - val_acc: 0.0000e+00\n",
            "Epoch 18/400\n",
            "80/80 [==============================] - 0s 745us/sample - loss: 0.0771 - acc: 0.0125 - val_loss: 0.0598 - val_acc: 0.0000e+00\n",
            "Epoch 19/400\n",
            "80/80 [==============================] - 0s 795us/sample - loss: 0.0765 - acc: 0.0125 - val_loss: 0.0592 - val_acc: 0.0000e+00\n",
            "Epoch 20/400\n",
            "80/80 [==============================] - 0s 853us/sample - loss: 0.0759 - acc: 0.0125 - val_loss: 0.0587 - val_acc: 0.0000e+00\n",
            "Epoch 21/400\n",
            "80/80 [==============================] - 0s 738us/sample - loss: 0.0751 - acc: 0.0125 - val_loss: 0.0581 - val_acc: 0.0000e+00\n",
            "Epoch 22/400\n",
            "80/80 [==============================] - 0s 748us/sample - loss: 0.0744 - acc: 0.0125 - val_loss: 0.0574 - val_acc: 0.0000e+00\n",
            "Epoch 23/400\n",
            "80/80 [==============================] - 0s 729us/sample - loss: 0.0736 - acc: 0.0125 - val_loss: 0.0567 - val_acc: 0.0000e+00\n",
            "Epoch 24/400\n",
            "80/80 [==============================] - 0s 772us/sample - loss: 0.0727 - acc: 0.0125 - val_loss: 0.0560 - val_acc: 0.0000e+00\n",
            "Epoch 25/400\n",
            "80/80 [==============================] - 0s 798us/sample - loss: 0.0717 - acc: 0.0125 - val_loss: 0.0554 - val_acc: 0.0000e+00\n",
            "Epoch 26/400\n",
            "80/80 [==============================] - 0s 800us/sample - loss: 0.0707 - acc: 0.0125 - val_loss: 0.0549 - val_acc: 0.0000e+00\n",
            "Epoch 27/400\n",
            "80/80 [==============================] - 0s 830us/sample - loss: 0.0695 - acc: 0.0125 - val_loss: 0.0543 - val_acc: 0.0000e+00\n",
            "Epoch 28/400\n",
            "80/80 [==============================] - 0s 818us/sample - loss: 0.0683 - acc: 0.0125 - val_loss: 0.0536 - val_acc: 0.0000e+00\n",
            "Epoch 29/400\n",
            "80/80 [==============================] - 0s 801us/sample - loss: 0.0669 - acc: 0.0125 - val_loss: 0.0527 - val_acc: 0.0000e+00\n",
            "Epoch 30/400\n",
            "80/80 [==============================] - 0s 895us/sample - loss: 0.0656 - acc: 0.0125 - val_loss: 0.0516 - val_acc: 0.0000e+00\n",
            "Epoch 31/400\n",
            "80/80 [==============================] - 0s 815us/sample - loss: 0.0640 - acc: 0.0125 - val_loss: 0.0503 - val_acc: 0.0000e+00\n",
            "Epoch 32/400\n",
            "80/80 [==============================] - 0s 816us/sample - loss: 0.0622 - acc: 0.0125 - val_loss: 0.0487 - val_acc: 0.0000e+00\n",
            "Epoch 33/400\n",
            "80/80 [==============================] - 0s 816us/sample - loss: 0.0604 - acc: 0.0125 - val_loss: 0.0469 - val_acc: 0.0000e+00\n",
            "Epoch 34/400\n",
            "80/80 [==============================] - 0s 790us/sample - loss: 0.0582 - acc: 0.0125 - val_loss: 0.0451 - val_acc: 0.0000e+00\n",
            "Epoch 35/400\n",
            "80/80 [==============================] - 0s 857us/sample - loss: 0.0560 - acc: 0.0125 - val_loss: 0.0431 - val_acc: 0.0000e+00\n",
            "Epoch 36/400\n",
            "80/80 [==============================] - 0s 810us/sample - loss: 0.0536 - acc: 0.0125 - val_loss: 0.0411 - val_acc: 0.0000e+00\n",
            "Epoch 37/400\n",
            "80/80 [==============================] - 0s 781us/sample - loss: 0.0511 - acc: 0.0125 - val_loss: 0.0390 - val_acc: 0.0000e+00\n",
            "Epoch 38/400\n",
            "80/80 [==============================] - 0s 795us/sample - loss: 0.0482 - acc: 0.0125 - val_loss: 0.0368 - val_acc: 0.0000e+00\n",
            "Epoch 39/400\n",
            "80/80 [==============================] - 0s 1ms/sample - loss: 0.0452 - acc: 0.0125 - val_loss: 0.0343 - val_acc: 0.0000e+00\n",
            "Epoch 40/400\n",
            "80/80 [==============================] - 0s 801us/sample - loss: 0.0421 - acc: 0.0125 - val_loss: 0.0317 - val_acc: 0.0000e+00\n",
            "Epoch 41/400\n",
            "80/80 [==============================] - 0s 917us/sample - loss: 0.0389 - acc: 0.0125 - val_loss: 0.0290 - val_acc: 0.0000e+00\n",
            "Epoch 42/400\n",
            "80/80 [==============================] - 0s 748us/sample - loss: 0.0355 - acc: 0.0125 - val_loss: 0.0263 - val_acc: 0.0000e+00\n",
            "Epoch 43/400\n",
            "80/80 [==============================] - 0s 800us/sample - loss: 0.0320 - acc: 0.0125 - val_loss: 0.0236 - val_acc: 0.0000e+00\n",
            "Epoch 44/400\n",
            "80/80 [==============================] - 0s 841us/sample - loss: 0.0283 - acc: 0.0125 - val_loss: 0.0208 - val_acc: 0.0000e+00\n",
            "Epoch 45/400\n",
            "80/80 [==============================] - 0s 780us/sample - loss: 0.0250 - acc: 0.0125 - val_loss: 0.0178 - val_acc: 0.0000e+00\n",
            "Epoch 46/400\n",
            "80/80 [==============================] - 0s 939us/sample - loss: 0.0217 - acc: 0.0125 - val_loss: 0.0149 - val_acc: 0.0000e+00\n",
            "Epoch 47/400\n",
            "80/80 [==============================] - 0s 784us/sample - loss: 0.0183 - acc: 0.0125 - val_loss: 0.0124 - val_acc: 0.0000e+00\n",
            "Epoch 48/400\n",
            "80/80 [==============================] - 0s 789us/sample - loss: 0.0155 - acc: 0.0125 - val_loss: 0.0102 - val_acc: 0.0000e+00\n",
            "Epoch 49/400\n",
            "80/80 [==============================] - 0s 979us/sample - loss: 0.0129 - acc: 0.0125 - val_loss: 0.0083 - val_acc: 0.0000e+00\n",
            "Epoch 50/400\n",
            "80/80 [==============================] - 0s 903us/sample - loss: 0.0106 - acc: 0.0125 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
            "Epoch 51/400\n",
            "80/80 [==============================] - 0s 706us/sample - loss: 0.0087 - acc: 0.0125 - val_loss: 0.0053 - val_acc: 0.0000e+00\n",
            "Epoch 52/400\n",
            "80/80 [==============================] - 0s 820us/sample - loss: 0.0071 - acc: 0.0125 - val_loss: 0.0042 - val_acc: 0.0000e+00\n",
            "Epoch 53/400\n",
            "80/80 [==============================] - 0s 800us/sample - loss: 0.0057 - acc: 0.0125 - val_loss: 0.0034 - val_acc: 0.0000e+00\n",
            "Epoch 54/400\n",
            "80/80 [==============================] - 0s 761us/sample - loss: 0.0048 - acc: 0.0125 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
            "Epoch 55/400\n",
            "80/80 [==============================] - 0s 898us/sample - loss: 0.0043 - acc: 0.0125 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
            "Epoch 56/400\n",
            "80/80 [==============================] - 0s 795us/sample - loss: 0.0040 - acc: 0.0125 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
            "Epoch 57/400\n",
            "80/80 [==============================] - 0s 980us/sample - loss: 0.0037 - acc: 0.0125 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
            "Epoch 58/400\n",
            "80/80 [==============================] - 0s 770us/sample - loss: 0.0036 - acc: 0.0125 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
            "Epoch 59/400\n",
            "80/80 [==============================] - 0s 789us/sample - loss: 0.0035 - acc: 0.0125 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
            "Epoch 60/400\n",
            "80/80 [==============================] - 0s 820us/sample - loss: 0.0035 - acc: 0.0125 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
            "Epoch 61/400\n",
            "80/80 [==============================] - 0s 813us/sample - loss: 0.0034 - acc: 0.0125 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
            "Epoch 62/400\n",
            "80/80 [==============================] - 0s 822us/sample - loss: 0.0034 - acc: 0.0125 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
            "Epoch 63/400\n",
            "80/80 [==============================] - 0s 973us/sample - loss: 0.0034 - acc: 0.0125 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
            "Epoch 64/400\n",
            "80/80 [==============================] - 0s 764us/sample - loss: 0.0033 - acc: 0.0125 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
            "Epoch 65/400\n",
            "80/80 [==============================] - 0s 838us/sample - loss: 0.0033 - acc: 0.0125 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
            "Epoch 66/400\n",
            "80/80 [==============================] - 0s 830us/sample - loss: 0.0033 - acc: 0.0125 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
            "Epoch 67/400\n",
            "80/80 [==============================] - 0s 724us/sample - loss: 0.0032 - acc: 0.0125 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
            "Epoch 68/400\n",
            "80/80 [==============================] - 0s 761us/sample - loss: 0.0032 - acc: 0.0125 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
            "Epoch 69/400\n",
            "80/80 [==============================] - 0s 791us/sample - loss: 0.0031 - acc: 0.0125 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
            "Epoch 70/400\n",
            "80/80 [==============================] - 0s 922us/sample - loss: 0.0031 - acc: 0.0125 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
            "Epoch 71/400\n",
            "80/80 [==============================] - 0s 758us/sample - loss: 0.0031 - acc: 0.0125 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
            "Epoch 72/400\n",
            "80/80 [==============================] - 0s 819us/sample - loss: 0.0030 - acc: 0.0125 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
            "Epoch 73/400\n",
            "80/80 [==============================] - 0s 840us/sample - loss: 0.0030 - acc: 0.0125 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
            "Epoch 74/400\n",
            "80/80 [==============================] - 0s 749us/sample - loss: 0.0029 - acc: 0.0125 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
            "Epoch 75/400\n",
            "80/80 [==============================] - 0s 786us/sample - loss: 0.0029 - acc: 0.0125 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
            "Epoch 76/400\n",
            "80/80 [==============================] - 0s 866us/sample - loss: 0.0029 - acc: 0.0125 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
            "Epoch 77/400\n",
            "80/80 [==============================] - 0s 739us/sample - loss: 0.0028 - acc: 0.0125 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
            "Epoch 78/400\n",
            "80/80 [==============================] - 0s 761us/sample - loss: 0.0028 - acc: 0.0125 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
            "Epoch 79/400\n",
            "80/80 [==============================] - 0s 873us/sample - loss: 0.0028 - acc: 0.0125 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
            "Epoch 80/400\n",
            "80/80 [==============================] - 0s 730us/sample - loss: 0.0028 - acc: 0.0125 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
            "Epoch 81/400\n",
            "80/80 [==============================] - 0s 1ms/sample - loss: 0.0027 - acc: 0.0125 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
            "Epoch 82/400\n",
            "80/80 [==============================] - 0s 803us/sample - loss: 0.0027 - acc: 0.0125 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
            "Epoch 83/400\n",
            "80/80 [==============================] - 0s 758us/sample - loss: 0.0027 - acc: 0.0125 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
            "Epoch 84/400\n",
            "80/80 [==============================] - 0s 809us/sample - loss: 0.0026 - acc: 0.0125 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
            "Epoch 85/400\n",
            "80/80 [==============================] - 0s 767us/sample - loss: 0.0026 - acc: 0.0125 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
            "Epoch 86/400\n",
            "80/80 [==============================] - 0s 841us/sample - loss: 0.0026 - acc: 0.0125 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
            "Epoch 87/400\n",
            "80/80 [==============================] - 0s 1ms/sample - loss: 0.0026 - acc: 0.0125 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
            "Epoch 88/400\n",
            "80/80 [==============================] - 0s 828us/sample - loss: 0.0025 - acc: 0.0125 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
            "Epoch 89/400\n",
            "80/80 [==============================] - 0s 849us/sample - loss: 0.0025 - acc: 0.0125 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
            "Epoch 90/400\n",
            "80/80 [==============================] - 0s 887us/sample - loss: 0.0025 - acc: 0.0125 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
            "Epoch 91/400\n",
            "80/80 [==============================] - 0s 823us/sample - loss: 0.0025 - acc: 0.0125 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
            "Epoch 92/400\n",
            "80/80 [==============================] - 0s 765us/sample - loss: 0.0025 - acc: 0.0125 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
            "Epoch 93/400\n",
            "80/80 [==============================] - 0s 749us/sample - loss: 0.0024 - acc: 0.0125 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
            "Epoch 94/400\n",
            "80/80 [==============================] - 0s 774us/sample - loss: 0.0024 - acc: 0.0125 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
            "Epoch 95/400\n",
            "80/80 [==============================] - 0s 799us/sample - loss: 0.0024 - acc: 0.0125 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
            "Epoch 96/400\n",
            "80/80 [==============================] - 0s 857us/sample - loss: 0.0024 - acc: 0.0125 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
            "Epoch 97/400\n",
            "80/80 [==============================] - 0s 764us/sample - loss: 0.0024 - acc: 0.0125 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
            "Epoch 98/400\n",
            "80/80 [==============================] - 0s 805us/sample - loss: 0.0023 - acc: 0.0125 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
            "Epoch 99/400\n",
            "80/80 [==============================] - 0s 730us/sample - loss: 0.0023 - acc: 0.0125 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
            "Epoch 100/400\n",
            "80/80 [==============================] - 0s 753us/sample - loss: 0.0023 - acc: 0.0125 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 101/400\n",
            "80/80 [==============================] - 0s 806us/sample - loss: 0.0023 - acc: 0.0125 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 102/400\n",
            "80/80 [==============================] - 0s 808us/sample - loss: 0.0023 - acc: 0.0125 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 103/400\n",
            "80/80 [==============================] - 0s 842us/sample - loss: 0.0022 - acc: 0.0125 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 104/400\n",
            "80/80 [==============================] - 0s 799us/sample - loss: 0.0022 - acc: 0.0125 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 105/400\n",
            "80/80 [==============================] - 0s 822us/sample - loss: 0.0022 - acc: 0.0125 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 106/400\n",
            "80/80 [==============================] - 0s 785us/sample - loss: 0.0022 - acc: 0.0125 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 107/400\n",
            "80/80 [==============================] - 0s 815us/sample - loss: 0.0022 - acc: 0.0125 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 108/400\n",
            "80/80 [==============================] - 0s 765us/sample - loss: 0.0022 - acc: 0.0125 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 109/400\n",
            "80/80 [==============================] - 0s 879us/sample - loss: 0.0021 - acc: 0.0125 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 110/400\n",
            "80/80 [==============================] - 0s 787us/sample - loss: 0.0021 - acc: 0.0125 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 111/400\n",
            "80/80 [==============================] - 0s 775us/sample - loss: 0.0021 - acc: 0.0125 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 112/400\n",
            "80/80 [==============================] - 0s 735us/sample - loss: 0.0021 - acc: 0.0125 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 113/400\n",
            "80/80 [==============================] - 0s 807us/sample - loss: 0.0021 - acc: 0.0125 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 114/400\n",
            "80/80 [==============================] - 0s 711us/sample - loss: 0.0021 - acc: 0.0125 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 115/400\n",
            "80/80 [==============================] - 0s 758us/sample - loss: 0.0020 - acc: 0.0125 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 116/400\n",
            "80/80 [==============================] - 0s 780us/sample - loss: 0.0020 - acc: 0.0125 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 117/400\n",
            "80/80 [==============================] - 0s 826us/sample - loss: 0.0020 - acc: 0.0125 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 118/400\n",
            "80/80 [==============================] - 0s 909us/sample - loss: 0.0020 - acc: 0.0125 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 119/400\n",
            "80/80 [==============================] - 0s 850us/sample - loss: 0.0020 - acc: 0.0125 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 120/400\n",
            "80/80 [==============================] - 0s 726us/sample - loss: 0.0020 - acc: 0.0125 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 121/400\n",
            "80/80 [==============================] - 0s 1ms/sample - loss: 0.0020 - acc: 0.0125 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 122/400\n",
            "80/80 [==============================] - 0s 851us/sample - loss: 0.0019 - acc: 0.0125 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 123/400\n",
            "80/80 [==============================] - 0s 756us/sample - loss: 0.0019 - acc: 0.0125 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 124/400\n",
            "80/80 [==============================] - 0s 906us/sample - loss: 0.0019 - acc: 0.0125 - val_loss: 0.0010 - val_acc: 0.0000e+00\n",
            "Epoch 125/400\n",
            "80/80 [==============================] - 0s 793us/sample - loss: 0.0019 - acc: 0.0125 - val_loss: 0.0010 - val_acc: 0.0000e+00\n",
            "Epoch 126/400\n",
            "80/80 [==============================] - 0s 742us/sample - loss: 0.0019 - acc: 0.0125 - val_loss: 0.0010 - val_acc: 0.0000e+00\n",
            "Epoch 127/400\n",
            "80/80 [==============================] - 0s 831us/sample - loss: 0.0019 - acc: 0.0125 - val_loss: 0.0010 - val_acc: 0.0000e+00\n",
            "Epoch 128/400\n",
            "80/80 [==============================] - 0s 735us/sample - loss: 0.0019 - acc: 0.0125 - val_loss: 0.0010 - val_acc: 0.0000e+00\n",
            "Epoch 129/400\n",
            "80/80 [==============================] - 0s 804us/sample - loss: 0.0019 - acc: 0.0125 - val_loss: 0.0010 - val_acc: 0.0000e+00\n",
            "Epoch 130/400\n",
            "80/80 [==============================] - 0s 726us/sample - loss: 0.0018 - acc: 0.0125 - val_loss: 9.8821e-04 - val_acc: 0.0000e+00\n",
            "Epoch 131/400\n",
            "80/80 [==============================] - 0s 787us/sample - loss: 0.0018 - acc: 0.0125 - val_loss: 9.9020e-04 - val_acc: 0.0000e+00\n",
            "Epoch 132/400\n",
            "80/80 [==============================] - 0s 800us/sample - loss: 0.0018 - acc: 0.0125 - val_loss: 9.8776e-04 - val_acc: 0.0000e+00\n",
            "Epoch 133/400\n",
            "80/80 [==============================] - 0s 822us/sample - loss: 0.0018 - acc: 0.0125 - val_loss: 9.7315e-04 - val_acc: 0.0000e+00\n",
            "Epoch 134/400\n",
            "80/80 [==============================] - 0s 844us/sample - loss: 0.0018 - acc: 0.0125 - val_loss: 9.6253e-04 - val_acc: 0.0000e+00\n",
            "Epoch 135/400\n",
            "80/80 [==============================] - 0s 830us/sample - loss: 0.0018 - acc: 0.0125 - val_loss: 9.3707e-04 - val_acc: 0.0000e+00\n",
            "Epoch 136/400\n",
            "80/80 [==============================] - 0s 781us/sample - loss: 0.0018 - acc: 0.0125 - val_loss: 9.2529e-04 - val_acc: 0.0000e+00\n",
            "Epoch 137/400\n",
            "80/80 [==============================] - 0s 798us/sample - loss: 0.0018 - acc: 0.0125 - val_loss: 9.2301e-04 - val_acc: 0.0000e+00\n",
            "Epoch 138/400\n",
            "80/80 [==============================] - 0s 788us/sample - loss: 0.0017 - acc: 0.0125 - val_loss: 9.1224e-04 - val_acc: 0.0000e+00\n",
            "Epoch 139/400\n",
            "80/80 [==============================] - 0s 803us/sample - loss: 0.0017 - acc: 0.0125 - val_loss: 9.2047e-04 - val_acc: 0.0000e+00\n",
            "Epoch 140/400\n",
            "80/80 [==============================] - 0s 944us/sample - loss: 0.0017 - acc: 0.0125 - val_loss: 9.3072e-04 - val_acc: 0.0000e+00\n",
            "Epoch 141/400\n",
            "80/80 [==============================] - 0s 827us/sample - loss: 0.0017 - acc: 0.0125 - val_loss: 9.2679e-04 - val_acc: 0.0000e+00\n",
            "Epoch 142/400\n",
            "80/80 [==============================] - 0s 756us/sample - loss: 0.0017 - acc: 0.0125 - val_loss: 9.0474e-04 - val_acc: 0.0000e+00\n",
            "Epoch 143/400\n",
            "80/80 [==============================] - 0s 788us/sample - loss: 0.0017 - acc: 0.0125 - val_loss: 8.8473e-04 - val_acc: 0.0000e+00\n",
            "Epoch 144/400\n",
            "80/80 [==============================] - 0s 734us/sample - loss: 0.0017 - acc: 0.0125 - val_loss: 8.7689e-04 - val_acc: 0.0000e+00\n",
            "Epoch 145/400\n",
            "80/80 [==============================] - 0s 816us/sample - loss: 0.0017 - acc: 0.0125 - val_loss: 8.7182e-04 - val_acc: 0.0000e+00\n",
            "Epoch 146/400\n",
            "80/80 [==============================] - 0s 1ms/sample - loss: 0.0017 - acc: 0.0125 - val_loss: 8.6724e-04 - val_acc: 0.0000e+00\n",
            "Epoch 147/400\n",
            "80/80 [==============================] - 0s 735us/sample - loss: 0.0016 - acc: 0.0125 - val_loss: 8.6489e-04 - val_acc: 0.0000e+00\n",
            "Epoch 148/400\n",
            "80/80 [==============================] - 0s 858us/sample - loss: 0.0016 - acc: 0.0125 - val_loss: 8.4903e-04 - val_acc: 0.0000e+00\n",
            "Epoch 149/400\n",
            "80/80 [==============================] - 0s 956us/sample - loss: 0.0016 - acc: 0.0125 - val_loss: 8.4033e-04 - val_acc: 0.0000e+00\n",
            "Epoch 150/400\n",
            "80/80 [==============================] - 0s 803us/sample - loss: 0.0016 - acc: 0.0125 - val_loss: 8.4246e-04 - val_acc: 0.0000e+00\n",
            "Epoch 151/400\n",
            "80/80 [==============================] - 0s 795us/sample - loss: 0.0016 - acc: 0.0125 - val_loss: 8.4304e-04 - val_acc: 0.0000e+00\n",
            "Epoch 152/400\n",
            "80/80 [==============================] - 0s 824us/sample - loss: 0.0016 - acc: 0.0125 - val_loss: 8.4035e-04 - val_acc: 0.0000e+00\n",
            "Epoch 153/400\n",
            "80/80 [==============================] - 0s 855us/sample - loss: 0.0016 - acc: 0.0125 - val_loss: 8.2382e-04 - val_acc: 0.0000e+00\n",
            "Epoch 154/400\n",
            "80/80 [==============================] - 0s 779us/sample - loss: 0.0016 - acc: 0.0125 - val_loss: 8.2256e-04 - val_acc: 0.0000e+00\n",
            "Epoch 155/400\n",
            "80/80 [==============================] - 0s 832us/sample - loss: 0.0016 - acc: 0.0125 - val_loss: 8.1991e-04 - val_acc: 0.0000e+00\n",
            "Epoch 156/400\n",
            "80/80 [==============================] - 0s 753us/sample - loss: 0.0016 - acc: 0.0125 - val_loss: 8.0532e-04 - val_acc: 0.0000e+00\n",
            "Epoch 157/400\n",
            "80/80 [==============================] - 0s 799us/sample - loss: 0.0015 - acc: 0.0125 - val_loss: 7.9597e-04 - val_acc: 0.0000e+00\n",
            "Epoch 158/400\n",
            "80/80 [==============================] - 0s 903us/sample - loss: 0.0015 - acc: 0.0125 - val_loss: 7.9111e-04 - val_acc: 0.0000e+00\n",
            "Epoch 159/400\n",
            "80/80 [==============================] - 0s 792us/sample - loss: 0.0015 - acc: 0.0125 - val_loss: 7.8856e-04 - val_acc: 0.0000e+00\n",
            "Epoch 160/400\n",
            "80/80 [==============================] - 0s 746us/sample - loss: 0.0015 - acc: 0.0125 - val_loss: 7.9221e-04 - val_acc: 0.0000e+00\n",
            "Epoch 161/400\n",
            "80/80 [==============================] - 0s 743us/sample - loss: 0.0015 - acc: 0.0125 - val_loss: 8.0121e-04 - val_acc: 0.0000e+00\n",
            "Epoch 162/400\n",
            "80/80 [==============================] - 0s 836us/sample - loss: 0.0015 - acc: 0.0125 - val_loss: 7.7157e-04 - val_acc: 0.0000e+00\n",
            "Epoch 163/400\n",
            "80/80 [==============================] - 0s 1ms/sample - loss: 0.0015 - acc: 0.0125 - val_loss: 7.5329e-04 - val_acc: 0.0000e+00\n",
            "Epoch 164/400\n",
            "80/80 [==============================] - 0s 754us/sample - loss: 0.0015 - acc: 0.0125 - val_loss: 7.4650e-04 - val_acc: 0.0000e+00\n",
            "Epoch 165/400\n",
            "80/80 [==============================] - 0s 831us/sample - loss: 0.0015 - acc: 0.0125 - val_loss: 7.4215e-04 - val_acc: 0.0000e+00\n",
            "Epoch 166/400\n",
            "80/80 [==============================] - 0s 769us/sample - loss: 0.0015 - acc: 0.0125 - val_loss: 7.4528e-04 - val_acc: 0.0000e+00\n",
            "Epoch 167/400\n",
            "80/80 [==============================] - 0s 756us/sample - loss: 0.0015 - acc: 0.0125 - val_loss: 7.5310e-04 - val_acc: 0.0000e+00\n",
            "Epoch 168/400\n",
            "80/80 [==============================] - 0s 861us/sample - loss: 0.0015 - acc: 0.0125 - val_loss: 7.4063e-04 - val_acc: 0.0000e+00\n",
            "Epoch 169/400\n",
            "80/80 [==============================] - 0s 753us/sample - loss: 0.0014 - acc: 0.0125 - val_loss: 7.3911e-04 - val_acc: 0.0000e+00\n",
            "Epoch 170/400\n",
            "80/80 [==============================] - 0s 913us/sample - loss: 0.0014 - acc: 0.0125 - val_loss: 7.1952e-04 - val_acc: 0.0000e+00\n",
            "Epoch 171/400\n",
            "80/80 [==============================] - 0s 806us/sample - loss: 0.0014 - acc: 0.0125 - val_loss: 7.0580e-04 - val_acc: 0.0000e+00\n",
            "Epoch 172/400\n",
            "80/80 [==============================] - 0s 787us/sample - loss: 0.0014 - acc: 0.0125 - val_loss: 6.9561e-04 - val_acc: 0.0000e+00\n",
            "Epoch 173/400\n",
            "80/80 [==============================] - 0s 790us/sample - loss: 0.0014 - acc: 0.0125 - val_loss: 6.9684e-04 - val_acc: 0.0000e+00\n",
            "Epoch 174/400\n",
            "80/80 [==============================] - 0s 752us/sample - loss: 0.0014 - acc: 0.0125 - val_loss: 6.8918e-04 - val_acc: 0.0000e+00\n",
            "Epoch 175/400\n",
            "80/80 [==============================] - 0s 821us/sample - loss: 0.0014 - acc: 0.0125 - val_loss: 6.8152e-04 - val_acc: 0.0000e+00\n",
            "Epoch 176/400\n",
            "80/80 [==============================] - 0s 960us/sample - loss: 0.0014 - acc: 0.0125 - val_loss: 6.8296e-04 - val_acc: 0.0000e+00\n",
            "Epoch 177/400\n",
            "80/80 [==============================] - 0s 774us/sample - loss: 0.0014 - acc: 0.0125 - val_loss: 6.8519e-04 - val_acc: 0.0000e+00\n",
            "Epoch 178/400\n",
            "80/80 [==============================] - 0s 809us/sample - loss: 0.0014 - acc: 0.0125 - val_loss: 6.8543e-04 - val_acc: 0.0000e+00\n",
            "Epoch 179/400\n",
            "80/80 [==============================] - 0s 777us/sample - loss: 0.0014 - acc: 0.0125 - val_loss: 6.7226e-04 - val_acc: 0.0000e+00\n",
            "Epoch 180/400\n",
            "80/80 [==============================] - 0s 755us/sample - loss: 0.0014 - acc: 0.0125 - val_loss: 6.7006e-04 - val_acc: 0.0000e+00\n",
            "Epoch 181/400\n",
            "80/80 [==============================] - 0s 812us/sample - loss: 0.0014 - acc: 0.0125 - val_loss: 6.6416e-04 - val_acc: 0.0000e+00\n",
            "Epoch 182/400\n",
            "80/80 [==============================] - 0s 788us/sample - loss: 0.0013 - acc: 0.0125 - val_loss: 6.8562e-04 - val_acc: 0.0000e+00\n",
            "Epoch 183/400\n",
            "80/80 [==============================] - 0s 960us/sample - loss: 0.0013 - acc: 0.0125 - val_loss: 7.0034e-04 - val_acc: 0.0000e+00\n",
            "Epoch 184/400\n",
            "80/80 [==============================] - 0s 854us/sample - loss: 0.0013 - acc: 0.0125 - val_loss: 6.8584e-04 - val_acc: 0.0000e+00\n",
            "Epoch 185/400\n",
            "80/80 [==============================] - 0s 781us/sample - loss: 0.0013 - acc: 0.0125 - val_loss: 6.5851e-04 - val_acc: 0.0000e+00\n",
            "Epoch 186/400\n",
            "80/80 [==============================] - 0s 1ms/sample - loss: 0.0013 - acc: 0.0125 - val_loss: 6.4450e-04 - val_acc: 0.0000e+00\n",
            "Epoch 187/400\n",
            "80/80 [==============================] - 0s 813us/sample - loss: 0.0013 - acc: 0.0125 - val_loss: 6.4180e-04 - val_acc: 0.0000e+00\n",
            "Epoch 188/400\n",
            "80/80 [==============================] - 0s 868us/sample - loss: 0.0013 - acc: 0.0125 - val_loss: 6.4250e-04 - val_acc: 0.0000e+00\n",
            "Epoch 189/400\n",
            "80/80 [==============================] - 0s 795us/sample - loss: 0.0013 - acc: 0.0125 - val_loss: 6.3422e-04 - val_acc: 0.0000e+00\n",
            "Epoch 190/400\n",
            "80/80 [==============================] - 0s 750us/sample - loss: 0.0013 - acc: 0.0125 - val_loss: 6.2268e-04 - val_acc: 0.0000e+00\n",
            "Epoch 191/400\n",
            "80/80 [==============================] - 0s 739us/sample - loss: 0.0013 - acc: 0.0125 - val_loss: 6.2027e-04 - val_acc: 0.0000e+00\n",
            "Epoch 192/400\n",
            "80/80 [==============================] - 0s 881us/sample - loss: 0.0013 - acc: 0.0125 - val_loss: 6.1428e-04 - val_acc: 0.0000e+00\n",
            "Epoch 193/400\n",
            "80/80 [==============================] - 0s 783us/sample - loss: 0.0013 - acc: 0.0125 - val_loss: 6.0851e-04 - val_acc: 0.0000e+00\n",
            "Epoch 194/400\n",
            "80/80 [==============================] - 0s 812us/sample - loss: 0.0013 - acc: 0.0125 - val_loss: 6.0358e-04 - val_acc: 0.0000e+00\n",
            "Epoch 195/400\n",
            "80/80 [==============================] - 0s 791us/sample - loss: 0.0013 - acc: 0.0125 - val_loss: 6.0340e-04 - val_acc: 0.0000e+00\n",
            "Epoch 196/400\n",
            "80/80 [==============================] - 0s 837us/sample - loss: 0.0013 - acc: 0.0125 - val_loss: 6.0939e-04 - val_acc: 0.0000e+00\n",
            "Epoch 197/400\n",
            "80/80 [==============================] - 0s 817us/sample - loss: 0.0012 - acc: 0.0125 - val_loss: 5.9959e-04 - val_acc: 0.0000e+00\n",
            "Epoch 198/400\n",
            "80/80 [==============================] - 0s 840us/sample - loss: 0.0012 - acc: 0.0125 - val_loss: 5.9037e-04 - val_acc: 0.0000e+00\n",
            "Epoch 199/400\n",
            "80/80 [==============================] - 0s 765us/sample - loss: 0.0012 - acc: 0.0125 - val_loss: 5.7291e-04 - val_acc: 0.0000e+00\n",
            "Epoch 200/400\n",
            "80/80 [==============================] - 0s 739us/sample - loss: 0.0012 - acc: 0.0125 - val_loss: 5.6492e-04 - val_acc: 0.0000e+00\n",
            "Epoch 201/400\n",
            "80/80 [==============================] - 0s 767us/sample - loss: 0.0012 - acc: 0.0125 - val_loss: 5.6779e-04 - val_acc: 0.0000e+00\n",
            "Epoch 202/400\n",
            "80/80 [==============================] - 0s 812us/sample - loss: 0.0012 - acc: 0.0125 - val_loss: 5.7761e-04 - val_acc: 0.0000e+00\n",
            "Epoch 203/400\n",
            "80/80 [==============================] - 0s 749us/sample - loss: 0.0012 - acc: 0.0125 - val_loss: 5.9621e-04 - val_acc: 0.0000e+00\n",
            "Epoch 204/400\n",
            "80/80 [==============================] - 0s 776us/sample - loss: 0.0012 - acc: 0.0125 - val_loss: 5.9340e-04 - val_acc: 0.0000e+00\n",
            "Epoch 205/400\n",
            "80/80 [==============================] - 0s 725us/sample - loss: 0.0012 - acc: 0.0125 - val_loss: 5.7358e-04 - val_acc: 0.0000e+00\n",
            "Epoch 206/400\n",
            "80/80 [==============================] - 0s 762us/sample - loss: 0.0012 - acc: 0.0125 - val_loss: 5.5921e-04 - val_acc: 0.0000e+00\n",
            "Epoch 207/400\n",
            "80/80 [==============================] - 0s 826us/sample - loss: 0.0012 - acc: 0.0125 - val_loss: 5.5529e-04 - val_acc: 0.0000e+00\n",
            "Epoch 208/400\n",
            "80/80 [==============================] - 0s 1ms/sample - loss: 0.0012 - acc: 0.0125 - val_loss: 5.6033e-04 - val_acc: 0.0000e+00\n",
            "Epoch 209/400\n",
            "80/80 [==============================] - 0s 778us/sample - loss: 0.0012 - acc: 0.0125 - val_loss: 5.6402e-04 - val_acc: 0.0000e+00\n",
            "Epoch 210/400\n",
            "80/80 [==============================] - 0s 735us/sample - loss: 0.0012 - acc: 0.0125 - val_loss: 5.6840e-04 - val_acc: 0.0000e+00\n",
            "Epoch 211/400\n",
            "80/80 [==============================] - 0s 801us/sample - loss: 0.0012 - acc: 0.0125 - val_loss: 5.6519e-04 - val_acc: 0.0000e+00\n",
            "Epoch 212/400\n",
            "80/80 [==============================] - 0s 772us/sample - loss: 0.0012 - acc: 0.0125 - val_loss: 5.3886e-04 - val_acc: 0.0000e+00\n",
            "Epoch 213/400\n",
            "80/80 [==============================] - 0s 738us/sample - loss: 0.0012 - acc: 0.0125 - val_loss: 5.2901e-04 - val_acc: 0.0000e+00\n",
            "Epoch 214/400\n",
            "80/80 [==============================] - 0s 858us/sample - loss: 0.0011 - acc: 0.0125 - val_loss: 5.2456e-04 - val_acc: 0.0000e+00\n",
            "Epoch 215/400\n",
            "80/80 [==============================] - 0s 700us/sample - loss: 0.0011 - acc: 0.0125 - val_loss: 5.2040e-04 - val_acc: 0.0000e+00\n",
            "Epoch 216/400\n",
            "80/80 [==============================] - 0s 757us/sample - loss: 0.0011 - acc: 0.0125 - val_loss: 5.1876e-04 - val_acc: 0.0000e+00\n",
            "Epoch 217/400\n",
            "80/80 [==============================] - 0s 864us/sample - loss: 0.0011 - acc: 0.0125 - val_loss: 5.2138e-04 - val_acc: 0.0000e+00\n",
            "Epoch 218/400\n",
            "80/80 [==============================] - 0s 777us/sample - loss: 0.0011 - acc: 0.0125 - val_loss: 5.2226e-04 - val_acc: 0.0000e+00\n",
            "Epoch 219/400\n",
            "80/80 [==============================] - 0s 808us/sample - loss: 0.0011 - acc: 0.0125 - val_loss: 5.1221e-04 - val_acc: 0.0000e+00\n",
            "Epoch 220/400\n",
            "80/80 [==============================] - 0s 904us/sample - loss: 0.0011 - acc: 0.0125 - val_loss: 5.0225e-04 - val_acc: 0.0000e+00\n",
            "Epoch 221/400\n",
            "80/80 [==============================] - 0s 860us/sample - loss: 0.0011 - acc: 0.0125 - val_loss: 4.9519e-04 - val_acc: 0.0000e+00\n",
            "Epoch 222/400\n",
            "80/80 [==============================] - 0s 794us/sample - loss: 0.0011 - acc: 0.0125 - val_loss: 4.9798e-04 - val_acc: 0.0000e+00\n",
            "Epoch 223/400\n",
            "80/80 [==============================] - 0s 787us/sample - loss: 0.0011 - acc: 0.0125 - val_loss: 4.9901e-04 - val_acc: 0.0000e+00\n",
            "Epoch 224/400\n",
            "80/80 [==============================] - 0s 805us/sample - loss: 0.0011 - acc: 0.0125 - val_loss: 5.1368e-04 - val_acc: 0.0000e+00\n",
            "Epoch 225/400\n",
            "80/80 [==============================] - 0s 914us/sample - loss: 0.0011 - acc: 0.0125 - val_loss: 5.1726e-04 - val_acc: 0.0000e+00\n",
            "Epoch 226/400\n",
            "80/80 [==============================] - 0s 761us/sample - loss: 0.0011 - acc: 0.0125 - val_loss: 5.1293e-04 - val_acc: 0.0000e+00\n",
            "Epoch 227/400\n",
            "80/80 [==============================] - 0s 754us/sample - loss: 0.0011 - acc: 0.0125 - val_loss: 4.8536e-04 - val_acc: 0.0000e+00\n",
            "Epoch 228/400\n",
            "80/80 [==============================] - 0s 950us/sample - loss: 0.0011 - acc: 0.0125 - val_loss: 4.7415e-04 - val_acc: 0.0000e+00\n",
            "Epoch 229/400\n",
            "80/80 [==============================] - 0s 820us/sample - loss: 0.0011 - acc: 0.0125 - val_loss: 4.7069e-04 - val_acc: 0.0000e+00\n",
            "Epoch 230/400\n",
            "80/80 [==============================] - 0s 758us/sample - loss: 0.0011 - acc: 0.0125 - val_loss: 4.7502e-04 - val_acc: 0.0000e+00\n",
            "Epoch 231/400\n",
            "80/80 [==============================] - 0s 799us/sample - loss: 0.0011 - acc: 0.0125 - val_loss: 4.9246e-04 - val_acc: 0.0000e+00\n",
            "Epoch 232/400\n",
            "80/80 [==============================] - 0s 932us/sample - loss: 0.0010 - acc: 0.0125 - val_loss: 4.9491e-04 - val_acc: 0.0000e+00\n",
            "Epoch 233/400\n",
            "80/80 [==============================] - 0s 780us/sample - loss: 0.0010 - acc: 0.0125 - val_loss: 4.8485e-04 - val_acc: 0.0000e+00\n",
            "Epoch 234/400\n",
            "80/80 [==============================] - 0s 840us/sample - loss: 0.0010 - acc: 0.0125 - val_loss: 4.6464e-04 - val_acc: 0.0000e+00\n",
            "Epoch 235/400\n",
            "80/80 [==============================] - 0s 878us/sample - loss: 0.0010 - acc: 0.0125 - val_loss: 4.5745e-04 - val_acc: 0.0000e+00\n",
            "Epoch 236/400\n",
            "80/80 [==============================] - 0s 781us/sample - loss: 0.0010 - acc: 0.0125 - val_loss: 4.6804e-04 - val_acc: 0.0000e+00\n",
            "Epoch 237/400\n",
            "80/80 [==============================] - 0s 720us/sample - loss: 0.0010 - acc: 0.0125 - val_loss: 4.5798e-04 - val_acc: 0.0000e+00\n",
            "Epoch 238/400\n",
            "80/80 [==============================] - 0s 741us/sample - loss: 0.0010 - acc: 0.0125 - val_loss: 4.6983e-04 - val_acc: 0.0000e+00\n",
            "Epoch 239/400\n",
            "80/80 [==============================] - 0s 793us/sample - loss: 0.0010 - acc: 0.0125 - val_loss: 4.6215e-04 - val_acc: 0.0000e+00\n",
            "Epoch 240/400\n",
            "80/80 [==============================] - 0s 781us/sample - loss: 0.0010 - acc: 0.0125 - val_loss: 4.5450e-04 - val_acc: 0.0000e+00\n",
            "Epoch 241/400\n",
            "80/80 [==============================] - 0s 882us/sample - loss: 0.0010 - acc: 0.0125 - val_loss: 4.5910e-04 - val_acc: 0.0000e+00\n",
            "Epoch 242/400\n",
            "80/80 [==============================] - 0s 776us/sample - loss: 9.9877e-04 - acc: 0.0125 - val_loss: 4.6698e-04 - val_acc: 0.0000e+00\n",
            "Epoch 243/400\n",
            "80/80 [==============================] - 0s 787us/sample - loss: 9.9235e-04 - acc: 0.0125 - val_loss: 4.6474e-04 - val_acc: 0.0000e+00\n",
            "Epoch 244/400\n",
            "80/80 [==============================] - 0s 789us/sample - loss: 9.8714e-04 - acc: 0.0125 - val_loss: 4.5546e-04 - val_acc: 0.0000e+00\n",
            "Epoch 245/400\n",
            "80/80 [==============================] - 0s 987us/sample - loss: 9.8356e-04 - acc: 0.0125 - val_loss: 4.4900e-04 - val_acc: 0.0000e+00\n",
            "Epoch 246/400\n",
            "80/80 [==============================] - 0s 887us/sample - loss: 9.7822e-04 - acc: 0.0125 - val_loss: 4.5831e-04 - val_acc: 0.0000e+00\n",
            "Epoch 247/400\n",
            "80/80 [==============================] - 0s 759us/sample - loss: 9.7319e-04 - acc: 0.0125 - val_loss: 4.5723e-04 - val_acc: 0.0000e+00\n",
            "Epoch 248/400\n",
            "80/80 [==============================] - 0s 769us/sample - loss: 9.6756e-04 - acc: 0.0125 - val_loss: 4.4549e-04 - val_acc: 0.0000e+00\n",
            "Epoch 249/400\n",
            "80/80 [==============================] - 0s 784us/sample - loss: 9.6139e-04 - acc: 0.0125 - val_loss: 4.2936e-04 - val_acc: 0.0000e+00\n",
            "Epoch 250/400\n",
            "80/80 [==============================] - 0s 826us/sample - loss: 9.5876e-04 - acc: 0.0125 - val_loss: 4.2171e-04 - val_acc: 0.0000e+00\n",
            "Epoch 251/400\n",
            "80/80 [==============================] - 0s 782us/sample - loss: 9.5562e-04 - acc: 0.0125 - val_loss: 4.2499e-04 - val_acc: 0.0000e+00\n",
            "Epoch 252/400\n",
            "80/80 [==============================] - 0s 763us/sample - loss: 9.4947e-04 - acc: 0.0125 - val_loss: 4.3696e-04 - val_acc: 0.0000e+00\n",
            "Epoch 253/400\n",
            "80/80 [==============================] - 0s 747us/sample - loss: 9.4420e-04 - acc: 0.0125 - val_loss: 4.3694e-04 - val_acc: 0.0000e+00\n",
            "Epoch 254/400\n",
            "80/80 [==============================] - 0s 833us/sample - loss: 9.4015e-04 - acc: 0.0125 - val_loss: 4.3619e-04 - val_acc: 0.0000e+00\n",
            "Epoch 255/400\n",
            "80/80 [==============================] - 0s 788us/sample - loss: 9.3641e-04 - acc: 0.0125 - val_loss: 4.2352e-04 - val_acc: 0.0000e+00\n",
            "Epoch 256/400\n",
            "80/80 [==============================] - 0s 840us/sample - loss: 9.3072e-04 - acc: 0.0125 - val_loss: 4.2549e-04 - val_acc: 0.0000e+00\n",
            "Epoch 257/400\n",
            "80/80 [==============================] - 0s 778us/sample - loss: 9.2601e-04 - acc: 0.0125 - val_loss: 4.2893e-04 - val_acc: 0.0000e+00\n",
            "Epoch 258/400\n",
            "80/80 [==============================] - 0s 771us/sample - loss: 9.2594e-04 - acc: 0.0125 - val_loss: 4.3686e-04 - val_acc: 0.0000e+00\n",
            "Epoch 259/400\n",
            "80/80 [==============================] - 0s 964us/sample - loss: 9.1827e-04 - acc: 0.0125 - val_loss: 4.1992e-04 - val_acc: 0.0000e+00\n",
            "Epoch 260/400\n",
            "80/80 [==============================] - 0s 824us/sample - loss: 9.1267e-04 - acc: 0.0125 - val_loss: 4.0748e-04 - val_acc: 0.0000e+00\n",
            "Epoch 261/400\n",
            "80/80 [==============================] - 0s 771us/sample - loss: 9.0933e-04 - acc: 0.0125 - val_loss: 4.0525e-04 - val_acc: 0.0000e+00\n",
            "Epoch 262/400\n",
            "80/80 [==============================] - 0s 767us/sample - loss: 9.0574e-04 - acc: 0.0125 - val_loss: 4.0231e-04 - val_acc: 0.0000e+00\n",
            "Epoch 263/400\n",
            "80/80 [==============================] - 0s 816us/sample - loss: 9.0265e-04 - acc: 0.0125 - val_loss: 4.1925e-04 - val_acc: 0.0000e+00\n",
            "Epoch 264/400\n",
            "80/80 [==============================] - 0s 763us/sample - loss: 8.9828e-04 - acc: 0.0125 - val_loss: 4.1833e-04 - val_acc: 0.0000e+00\n",
            "Epoch 265/400\n",
            "80/80 [==============================] - 0s 766us/sample - loss: 8.9315e-04 - acc: 0.0125 - val_loss: 4.0557e-04 - val_acc: 0.0000e+00\n",
            "Epoch 266/400\n",
            "80/80 [==============================] - 0s 929us/sample - loss: 8.8478e-04 - acc: 0.0125 - val_loss: 3.8870e-04 - val_acc: 0.0000e+00\n",
            "Epoch 267/400\n",
            "80/80 [==============================] - 0s 745us/sample - loss: 8.8650e-04 - acc: 0.0125 - val_loss: 3.8157e-04 - val_acc: 0.0000e+00\n",
            "Epoch 268/400\n",
            "80/80 [==============================] - 0s 820us/sample - loss: 8.8215e-04 - acc: 0.0125 - val_loss: 3.9034e-04 - val_acc: 0.0000e+00\n",
            "Epoch 269/400\n",
            "80/80 [==============================] - 0s 814us/sample - loss: 8.7357e-04 - acc: 0.0125 - val_loss: 4.1020e-04 - val_acc: 0.0000e+00\n",
            "Epoch 270/400\n",
            "80/80 [==============================] - 0s 755us/sample - loss: 8.7167e-04 - acc: 0.0125 - val_loss: 4.2019e-04 - val_acc: 0.0000e+00\n",
            "Epoch 271/400\n",
            "80/80 [==============================] - 0s 800us/sample - loss: 8.6977e-04 - acc: 0.0125 - val_loss: 4.0945e-04 - val_acc: 0.0000e+00\n",
            "Epoch 272/400\n",
            "80/80 [==============================] - 0s 985us/sample - loss: 8.6754e-04 - acc: 0.0125 - val_loss: 4.0117e-04 - val_acc: 0.0000e+00\n",
            "Epoch 273/400\n",
            "80/80 [==============================] - 0s 993us/sample - loss: 8.6612e-04 - acc: 0.0125 - val_loss: 3.7025e-04 - val_acc: 0.0000e+00\n",
            "Epoch 274/400\n",
            "80/80 [==============================] - 0s 794us/sample - loss: 8.5639e-04 - acc: 0.0125 - val_loss: 3.7377e-04 - val_acc: 0.0000e+00\n",
            "Epoch 275/400\n",
            "80/80 [==============================] - 0s 789us/sample - loss: 8.5050e-04 - acc: 0.0125 - val_loss: 3.9252e-04 - val_acc: 0.0000e+00\n",
            "Epoch 276/400\n",
            "80/80 [==============================] - 0s 764us/sample - loss: 8.4656e-04 - acc: 0.0125 - val_loss: 3.9294e-04 - val_acc: 0.0000e+00\n",
            "Epoch 277/400\n",
            "80/80 [==============================] - 0s 740us/sample - loss: 8.4219e-04 - acc: 0.0125 - val_loss: 3.9103e-04 - val_acc: 0.0000e+00\n",
            "Epoch 278/400\n",
            "80/80 [==============================] - 0s 867us/sample - loss: 8.3678e-04 - acc: 0.0125 - val_loss: 3.7749e-04 - val_acc: 0.0000e+00\n",
            "Epoch 279/400\n",
            "80/80 [==============================] - 0s 955us/sample - loss: 8.3195e-04 - acc: 0.0125 - val_loss: 3.6493e-04 - val_acc: 0.0000e+00\n",
            "Epoch 280/400\n",
            "80/80 [==============================] - 0s 864us/sample - loss: 8.2906e-04 - acc: 0.0125 - val_loss: 3.6152e-04 - val_acc: 0.0000e+00\n",
            "Epoch 281/400\n",
            "80/80 [==============================] - 0s 786us/sample - loss: 8.2513e-04 - acc: 0.0125 - val_loss: 3.6939e-04 - val_acc: 0.0000e+00\n",
            "Epoch 282/400\n",
            "80/80 [==============================] - 0s 792us/sample - loss: 8.2119e-04 - acc: 0.0125 - val_loss: 3.6891e-04 - val_acc: 0.0000e+00\n",
            "Epoch 283/400\n",
            "80/80 [==============================] - 0s 771us/sample - loss: 8.1589e-04 - acc: 0.0125 - val_loss: 3.6337e-04 - val_acc: 0.0000e+00\n",
            "Epoch 284/400\n",
            "80/80 [==============================] - 0s 765us/sample - loss: 8.1329e-04 - acc: 0.0125 - val_loss: 3.5779e-04 - val_acc: 0.0000e+00\n",
            "Epoch 285/400\n",
            "80/80 [==============================] - 0s 848us/sample - loss: 8.0979e-04 - acc: 0.0125 - val_loss: 3.6322e-04 - val_acc: 0.0000e+00\n",
            "Epoch 286/400\n",
            "80/80 [==============================] - 0s 952us/sample - loss: 8.0431e-04 - acc: 0.0125 - val_loss: 3.5538e-04 - val_acc: 0.0000e+00\n",
            "Epoch 287/400\n",
            "80/80 [==============================] - 0s 779us/sample - loss: 8.0157e-04 - acc: 0.0125 - val_loss: 3.4620e-04 - val_acc: 0.0000e+00\n",
            "Epoch 288/400\n",
            "80/80 [==============================] - 0s 867us/sample - loss: 7.9806e-04 - acc: 0.0125 - val_loss: 3.4658e-04 - val_acc: 0.0000e+00\n",
            "Epoch 289/400\n",
            "80/80 [==============================] - 0s 798us/sample - loss: 7.9372e-04 - acc: 0.0125 - val_loss: 3.4644e-04 - val_acc: 0.0000e+00\n",
            "Epoch 290/400\n",
            "80/80 [==============================] - 0s 839us/sample - loss: 7.9003e-04 - acc: 0.0125 - val_loss: 3.4921e-04 - val_acc: 0.0000e+00\n",
            "Epoch 291/400\n",
            "80/80 [==============================] - 0s 814us/sample - loss: 7.8785e-04 - acc: 0.0125 - val_loss: 3.4614e-04 - val_acc: 0.0000e+00\n",
            "Epoch 292/400\n",
            "80/80 [==============================] - 0s 728us/sample - loss: 7.8334e-04 - acc: 0.0125 - val_loss: 3.3127e-04 - val_acc: 0.0000e+00\n",
            "Epoch 293/400\n",
            "80/80 [==============================] - 0s 909us/sample - loss: 7.8010e-04 - acc: 0.0125 - val_loss: 3.3571e-04 - val_acc: 0.0000e+00\n",
            "Epoch 294/400\n",
            "80/80 [==============================] - 0s 770us/sample - loss: 7.7729e-04 - acc: 0.0125 - val_loss: 3.4873e-04 - val_acc: 0.0000e+00\n",
            "Epoch 295/400\n",
            "80/80 [==============================] - 0s 763us/sample - loss: 7.7161e-04 - acc: 0.0125 - val_loss: 3.4025e-04 - val_acc: 0.0000e+00\n",
            "Epoch 296/400\n",
            "80/80 [==============================] - 0s 869us/sample - loss: 7.6923e-04 - acc: 0.0125 - val_loss: 3.2994e-04 - val_acc: 0.0000e+00\n",
            "Epoch 297/400\n",
            "80/80 [==============================] - 0s 987us/sample - loss: 7.6556e-04 - acc: 0.0125 - val_loss: 3.3418e-04 - val_acc: 0.0000e+00\n",
            "Epoch 298/400\n",
            "80/80 [==============================] - 0s 719us/sample - loss: 7.6136e-04 - acc: 0.0125 - val_loss: 3.2930e-04 - val_acc: 0.0000e+00\n",
            "Epoch 299/400\n",
            "80/80 [==============================] - 0s 750us/sample - loss: 7.5855e-04 - acc: 0.0125 - val_loss: 3.3066e-04 - val_acc: 0.0000e+00\n",
            "Epoch 300/400\n",
            "80/80 [==============================] - 0s 812us/sample - loss: 7.5488e-04 - acc: 0.0125 - val_loss: 3.1942e-04 - val_acc: 0.0000e+00\n",
            "Epoch 301/400\n",
            "80/80 [==============================] - 0s 888us/sample - loss: 7.5349e-04 - acc: 0.0125 - val_loss: 3.1715e-04 - val_acc: 0.0000e+00\n",
            "Epoch 302/400\n",
            "80/80 [==============================] - 0s 829us/sample - loss: 7.5318e-04 - acc: 0.0125 - val_loss: 3.3576e-04 - val_acc: 0.0000e+00\n",
            "Epoch 303/400\n",
            "80/80 [==============================] - 0s 748us/sample - loss: 7.4721e-04 - acc: 0.0125 - val_loss: 3.2403e-04 - val_acc: 0.0000e+00\n",
            "Epoch 304/400\n",
            "80/80 [==============================] - 0s 769us/sample - loss: 7.3903e-04 - acc: 0.0125 - val_loss: 3.0691e-04 - val_acc: 0.0000e+00\n",
            "Epoch 305/400\n",
            "80/80 [==============================] - 0s 824us/sample - loss: 7.3887e-04 - acc: 0.0125 - val_loss: 3.0214e-04 - val_acc: 0.0000e+00\n",
            "Epoch 306/400\n",
            "80/80 [==============================] - 0s 837us/sample - loss: 7.3703e-04 - acc: 0.0125 - val_loss: 3.0299e-04 - val_acc: 0.0000e+00\n",
            "Epoch 307/400\n",
            "80/80 [==============================] - 0s 824us/sample - loss: 7.3218e-04 - acc: 0.0125 - val_loss: 3.1604e-04 - val_acc: 0.0000e+00\n",
            "Epoch 308/400\n",
            "80/80 [==============================] - 0s 780us/sample - loss: 7.2981e-04 - acc: 0.0125 - val_loss: 3.3955e-04 - val_acc: 0.0000e+00\n",
            "Epoch 309/400\n",
            "80/80 [==============================] - 0s 781us/sample - loss: 7.3058e-04 - acc: 0.0125 - val_loss: 3.2250e-04 - val_acc: 0.0000e+00\n",
            "Epoch 310/400\n",
            "80/80 [==============================] - 0s 785us/sample - loss: 7.2357e-04 - acc: 0.0125 - val_loss: 2.9181e-04 - val_acc: 0.0000e+00\n",
            "Epoch 311/400\n",
            "80/80 [==============================] - 0s 823us/sample - loss: 7.2306e-04 - acc: 0.0125 - val_loss: 2.8879e-04 - val_acc: 0.0000e+00\n",
            "Epoch 312/400\n",
            "80/80 [==============================] - 0s 819us/sample - loss: 7.2073e-04 - acc: 0.0125 - val_loss: 2.9522e-04 - val_acc: 0.0000e+00\n",
            "Epoch 313/400\n",
            "80/80 [==============================] - 0s 739us/sample - loss: 7.1018e-04 - acc: 0.0125 - val_loss: 3.0640e-04 - val_acc: 0.0000e+00\n",
            "Epoch 314/400\n",
            "80/80 [==============================] - 0s 785us/sample - loss: 7.0968e-04 - acc: 0.0125 - val_loss: 3.1487e-04 - val_acc: 0.0000e+00\n",
            "Epoch 315/400\n",
            "80/80 [==============================] - 0s 762us/sample - loss: 7.0861e-04 - acc: 0.0125 - val_loss: 2.9900e-04 - val_acc: 0.0000e+00\n",
            "Epoch 316/400\n",
            "80/80 [==============================] - 0s 737us/sample - loss: 7.0042e-04 - acc: 0.0125 - val_loss: 2.9941e-04 - val_acc: 0.0000e+00\n",
            "Epoch 317/400\n",
            "80/80 [==============================] - 0s 778us/sample - loss: 6.9733e-04 - acc: 0.0125 - val_loss: 2.9958e-04 - val_acc: 0.0000e+00\n",
            "Epoch 318/400\n",
            "80/80 [==============================] - 0s 806us/sample - loss: 6.9562e-04 - acc: 0.0125 - val_loss: 2.9733e-04 - val_acc: 0.0000e+00\n",
            "Epoch 319/400\n",
            "80/80 [==============================] - 0s 818us/sample - loss: 6.9265e-04 - acc: 0.0125 - val_loss: 2.9259e-04 - val_acc: 0.0000e+00\n",
            "Epoch 320/400\n",
            "80/80 [==============================] - 0s 794us/sample - loss: 6.8827e-04 - acc: 0.0125 - val_loss: 2.9575e-04 - val_acc: 0.0000e+00\n",
            "Epoch 321/400\n",
            "80/80 [==============================] - 0s 772us/sample - loss: 6.8622e-04 - acc: 0.0125 - val_loss: 2.9309e-04 - val_acc: 0.0000e+00\n",
            "Epoch 322/400\n",
            "80/80 [==============================] - 0s 769us/sample - loss: 6.8198e-04 - acc: 0.0125 - val_loss: 2.8631e-04 - val_acc: 0.0000e+00\n",
            "Epoch 323/400\n",
            "80/80 [==============================] - 0s 749us/sample - loss: 6.7811e-04 - acc: 0.0125 - val_loss: 2.8468e-04 - val_acc: 0.0000e+00\n",
            "Epoch 324/400\n",
            "80/80 [==============================] - 0s 835us/sample - loss: 6.7570e-04 - acc: 0.0125 - val_loss: 2.8343e-04 - val_acc: 0.0000e+00\n",
            "Epoch 325/400\n",
            "80/80 [==============================] - 0s 873us/sample - loss: 6.7384e-04 - acc: 0.0125 - val_loss: 2.7372e-04 - val_acc: 0.0000e+00\n",
            "Epoch 326/400\n",
            "80/80 [==============================] - 0s 780us/sample - loss: 6.6946e-04 - acc: 0.0125 - val_loss: 2.7260e-04 - val_acc: 0.0000e+00\n",
            "Epoch 327/400\n",
            "80/80 [==============================] - 0s 802us/sample - loss: 6.6580e-04 - acc: 0.0125 - val_loss: 2.7056e-04 - val_acc: 0.0000e+00\n",
            "Epoch 328/400\n",
            "80/80 [==============================] - 0s 874us/sample - loss: 6.6304e-04 - acc: 0.0125 - val_loss: 2.6824e-04 - val_acc: 0.0000e+00\n",
            "Epoch 329/400\n",
            "80/80 [==============================] - 0s 788us/sample - loss: 6.5939e-04 - acc: 0.0125 - val_loss: 2.7515e-04 - val_acc: 0.0000e+00\n",
            "Epoch 330/400\n",
            "80/80 [==============================] - 0s 773us/sample - loss: 6.5841e-04 - acc: 0.0125 - val_loss: 2.8546e-04 - val_acc: 0.0000e+00\n",
            "Epoch 331/400\n",
            "80/80 [==============================] - 0s 756us/sample - loss: 6.6178e-04 - acc: 0.0125 - val_loss: 3.0221e-04 - val_acc: 0.0000e+00\n",
            "Epoch 332/400\n",
            "80/80 [==============================] - 0s 729us/sample - loss: 6.5653e-04 - acc: 0.0125 - val_loss: 2.7311e-04 - val_acc: 0.0000e+00\n",
            "Epoch 333/400\n",
            "80/80 [==============================] - 0s 779us/sample - loss: 6.5070e-04 - acc: 0.0125 - val_loss: 2.4962e-04 - val_acc: 0.0000e+00\n",
            "Epoch 334/400\n",
            "80/80 [==============================] - 0s 739us/sample - loss: 6.5222e-04 - acc: 0.0125 - val_loss: 2.4859e-04 - val_acc: 0.0000e+00\n",
            "Epoch 335/400\n",
            "80/80 [==============================] - 0s 815us/sample - loss: 6.4712e-04 - acc: 0.0125 - val_loss: 2.6071e-04 - val_acc: 0.0000e+00\n",
            "Epoch 336/400\n",
            "80/80 [==============================] - 0s 886us/sample - loss: 6.3939e-04 - acc: 0.0125 - val_loss: 2.6033e-04 - val_acc: 0.0000e+00\n",
            "Epoch 337/400\n",
            "80/80 [==============================] - 0s 779us/sample - loss: 6.3666e-04 - acc: 0.0125 - val_loss: 2.5588e-04 - val_acc: 0.0000e+00\n",
            "Epoch 338/400\n",
            "80/80 [==============================] - 0s 815us/sample - loss: 6.3320e-04 - acc: 0.0125 - val_loss: 2.5136e-04 - val_acc: 0.0000e+00\n",
            "Epoch 339/400\n",
            "80/80 [==============================] - 0s 800us/sample - loss: 6.3079e-04 - acc: 0.0125 - val_loss: 2.5000e-04 - val_acc: 0.0000e+00\n",
            "Epoch 340/400\n",
            "80/80 [==============================] - 0s 854us/sample - loss: 6.2756e-04 - acc: 0.0125 - val_loss: 2.4719e-04 - val_acc: 0.0000e+00\n",
            "Epoch 341/400\n",
            "80/80 [==============================] - 0s 823us/sample - loss: 6.2427e-04 - acc: 0.0125 - val_loss: 2.5574e-04 - val_acc: 0.0000e+00\n",
            "Epoch 342/400\n",
            "80/80 [==============================] - 0s 772us/sample - loss: 6.2151e-04 - acc: 0.0125 - val_loss: 2.5682e-04 - val_acc: 0.0000e+00\n",
            "Epoch 343/400\n",
            "80/80 [==============================] - 0s 748us/sample - loss: 6.1974e-04 - acc: 0.0125 - val_loss: 2.5718e-04 - val_acc: 0.0000e+00\n",
            "Epoch 344/400\n",
            "80/80 [==============================] - 0s 800us/sample - loss: 6.1692e-04 - acc: 0.0125 - val_loss: 2.4647e-04 - val_acc: 0.0000e+00\n",
            "Epoch 345/400\n",
            "80/80 [==============================] - 0s 838us/sample - loss: 6.1370e-04 - acc: 0.0125 - val_loss: 2.4620e-04 - val_acc: 0.0000e+00\n",
            "Epoch 346/400\n",
            "80/80 [==============================] - 0s 970us/sample - loss: 6.0882e-04 - acc: 0.0125 - val_loss: 2.3784e-04 - val_acc: 0.0000e+00\n",
            "Epoch 347/400\n",
            "80/80 [==============================] - 0s 752us/sample - loss: 6.0815e-04 - acc: 0.0125 - val_loss: 2.3415e-04 - val_acc: 0.0000e+00\n",
            "Epoch 348/400\n",
            "80/80 [==============================] - 0s 735us/sample - loss: 6.0520e-04 - acc: 0.0125 - val_loss: 2.3879e-04 - val_acc: 0.0000e+00\n",
            "Epoch 349/400\n",
            "80/80 [==============================] - 0s 847us/sample - loss: 6.0444e-04 - acc: 0.0125 - val_loss: 2.4963e-04 - val_acc: 0.0000e+00\n",
            "Epoch 350/400\n",
            "80/80 [==============================] - 0s 779us/sample - loss: 5.9965e-04 - acc: 0.0125 - val_loss: 2.3900e-04 - val_acc: 0.0000e+00\n",
            "Epoch 351/400\n",
            "80/80 [==============================] - 0s 778us/sample - loss: 5.9538e-04 - acc: 0.0125 - val_loss: 2.3282e-04 - val_acc: 0.0000e+00\n",
            "Epoch 352/400\n",
            "80/80 [==============================] - 0s 880us/sample - loss: 5.9389e-04 - acc: 0.0125 - val_loss: 2.2671e-04 - val_acc: 0.0000e+00\n",
            "Epoch 353/400\n",
            "80/80 [==============================] - 0s 775us/sample - loss: 5.9589e-04 - acc: 0.0125 - val_loss: 2.2373e-04 - val_acc: 0.0000e+00\n",
            "Epoch 354/400\n",
            "80/80 [==============================] - 0s 738us/sample - loss: 5.8832e-04 - acc: 0.0125 - val_loss: 2.4057e-04 - val_acc: 0.0000e+00\n",
            "Epoch 355/400\n",
            "80/80 [==============================] - 0s 791us/sample - loss: 5.8502e-04 - acc: 0.0125 - val_loss: 2.4600e-04 - val_acc: 0.0000e+00\n",
            "Epoch 356/400\n",
            "80/80 [==============================] - 0s 816us/sample - loss: 5.8563e-04 - acc: 0.0125 - val_loss: 2.3929e-04 - val_acc: 0.0000e+00\n",
            "Epoch 357/400\n",
            "80/80 [==============================] - 0s 793us/sample - loss: 5.8147e-04 - acc: 0.0125 - val_loss: 2.2641e-04 - val_acc: 0.0000e+00\n",
            "Epoch 358/400\n",
            "80/80 [==============================] - 0s 811us/sample - loss: 5.7753e-04 - acc: 0.0125 - val_loss: 2.2224e-04 - val_acc: 0.0000e+00\n",
            "Epoch 359/400\n",
            "80/80 [==============================] - 0s 828us/sample - loss: 5.7383e-04 - acc: 0.0125 - val_loss: 2.1568e-04 - val_acc: 0.0000e+00\n",
            "Epoch 360/400\n",
            "80/80 [==============================] - 0s 775us/sample - loss: 5.7320e-04 - acc: 0.0125 - val_loss: 2.1374e-04 - val_acc: 0.0000e+00\n",
            "Epoch 361/400\n",
            "80/80 [==============================] - 0s 750us/sample - loss: 5.7073e-04 - acc: 0.0125 - val_loss: 2.1811e-04 - val_acc: 0.0000e+00\n",
            "Epoch 362/400\n",
            "80/80 [==============================] - 0s 764us/sample - loss: 5.6432e-04 - acc: 0.0125 - val_loss: 2.3105e-04 - val_acc: 0.0000e+00\n",
            "Epoch 363/400\n",
            "80/80 [==============================] - 0s 769us/sample - loss: 5.6468e-04 - acc: 0.0125 - val_loss: 2.3240e-04 - val_acc: 0.0000e+00\n",
            "Epoch 364/400\n",
            "80/80 [==============================] - 0s 802us/sample - loss: 5.6262e-04 - acc: 0.0125 - val_loss: 2.2460e-04 - val_acc: 0.0000e+00\n",
            "Epoch 365/400\n",
            "80/80 [==============================] - 0s 879us/sample - loss: 5.5736e-04 - acc: 0.0125 - val_loss: 2.1427e-04 - val_acc: 0.0000e+00\n",
            "Epoch 366/400\n",
            "80/80 [==============================] - 0s 802us/sample - loss: 5.5531e-04 - acc: 0.0125 - val_loss: 2.0661e-04 - val_acc: 0.0000e+00\n",
            "Epoch 367/400\n",
            "80/80 [==============================] - 0s 835us/sample - loss: 5.5625e-04 - acc: 0.0125 - val_loss: 2.0559e-04 - val_acc: 0.0000e+00\n",
            "Epoch 368/400\n",
            "80/80 [==============================] - 0s 780us/sample - loss: 5.5181e-04 - acc: 0.0125 - val_loss: 2.1286e-04 - val_acc: 0.0000e+00\n",
            "Epoch 369/400\n",
            "80/80 [==============================] - 0s 794us/sample - loss: 5.4717e-04 - acc: 0.0125 - val_loss: 2.1793e-04 - val_acc: 0.0000e+00\n",
            "Epoch 370/400\n",
            "80/80 [==============================] - 0s 831us/sample - loss: 5.4555e-04 - acc: 0.0125 - val_loss: 2.1269e-04 - val_acc: 0.0000e+00\n",
            "Epoch 371/400\n",
            "80/80 [==============================] - 0s 796us/sample - loss: 5.4306e-04 - acc: 0.0125 - val_loss: 2.0700e-04 - val_acc: 0.0000e+00\n",
            "Epoch 372/400\n",
            "80/80 [==============================] - 0s 797us/sample - loss: 5.4090e-04 - acc: 0.0125 - val_loss: 2.0548e-04 - val_acc: 0.0000e+00\n",
            "Epoch 373/400\n",
            "80/80 [==============================] - 0s 746us/sample - loss: 5.4231e-04 - acc: 0.0125 - val_loss: 2.1285e-04 - val_acc: 0.0000e+00\n",
            "Epoch 374/400\n",
            "80/80 [==============================] - 0s 762us/sample - loss: 5.3470e-04 - acc: 0.0125 - val_loss: 1.9998e-04 - val_acc: 0.0000e+00\n",
            "Epoch 375/400\n",
            "80/80 [==============================] - 0s 863us/sample - loss: 5.3340e-04 - acc: 0.0125 - val_loss: 1.9665e-04 - val_acc: 0.0000e+00\n",
            "Epoch 376/400\n",
            "80/80 [==============================] - 0s 845us/sample - loss: 5.3189e-04 - acc: 0.0125 - val_loss: 1.9491e-04 - val_acc: 0.0000e+00\n",
            "Epoch 377/400\n",
            "80/80 [==============================] - 0s 809us/sample - loss: 5.2957e-04 - acc: 0.0125 - val_loss: 1.9484e-04 - val_acc: 0.0000e+00\n",
            "Epoch 378/400\n",
            "80/80 [==============================] - 0s 917us/sample - loss: 5.2602e-04 - acc: 0.0125 - val_loss: 1.9953e-04 - val_acc: 0.0000e+00\n",
            "Epoch 379/400\n",
            "80/80 [==============================] - 0s 1ms/sample - loss: 5.2381e-04 - acc: 0.0125 - val_loss: 1.9829e-04 - val_acc: 0.0000e+00\n",
            "Epoch 380/400\n",
            "80/80 [==============================] - 0s 843us/sample - loss: 5.2385e-04 - acc: 0.0125 - val_loss: 2.0113e-04 - val_acc: 0.0000e+00\n",
            "Epoch 381/400\n",
            "80/80 [==============================] - 0s 739us/sample - loss: 5.1732e-04 - acc: 0.0125 - val_loss: 1.8718e-04 - val_acc: 0.0000e+00\n",
            "Epoch 382/400\n",
            "80/80 [==============================] - 0s 758us/sample - loss: 5.1770e-04 - acc: 0.0125 - val_loss: 1.8196e-04 - val_acc: 0.0000e+00\n",
            "Epoch 383/400\n",
            "80/80 [==============================] - 0s 865us/sample - loss: 5.2218e-04 - acc: 0.0125 - val_loss: 1.8346e-04 - val_acc: 0.0000e+00\n",
            "Epoch 384/400\n",
            "80/80 [==============================] - 0s 840us/sample - loss: 5.1430e-04 - acc: 0.0125 - val_loss: 1.8706e-04 - val_acc: 0.0000e+00\n",
            "Epoch 385/400\n",
            "80/80 [==============================] - 0s 766us/sample - loss: 5.0864e-04 - acc: 0.0125 - val_loss: 1.9181e-04 - val_acc: 0.0000e+00\n",
            "Epoch 386/400\n",
            "80/80 [==============================] - 0s 821us/sample - loss: 5.0885e-04 - acc: 0.0125 - val_loss: 1.9612e-04 - val_acc: 0.0000e+00\n",
            "Epoch 387/400\n",
            "80/80 [==============================] - 0s 879us/sample - loss: 5.0585e-04 - acc: 0.0125 - val_loss: 1.8456e-04 - val_acc: 0.0000e+00\n",
            "Epoch 388/400\n",
            "80/80 [==============================] - 0s 813us/sample - loss: 5.0478e-04 - acc: 0.0125 - val_loss: 1.8064e-04 - val_acc: 0.0000e+00\n",
            "Epoch 389/400\n",
            "80/80 [==============================] - 0s 786us/sample - loss: 5.0054e-04 - acc: 0.0125 - val_loss: 1.8996e-04 - val_acc: 0.0000e+00\n",
            "Epoch 390/400\n",
            "80/80 [==============================] - 0s 772us/sample - loss: 4.9960e-04 - acc: 0.0125 - val_loss: 1.8636e-04 - val_acc: 0.0000e+00\n",
            "Epoch 391/400\n",
            "80/80 [==============================] - 0s 987us/sample - loss: 4.9659e-04 - acc: 0.0125 - val_loss: 1.8748e-04 - val_acc: 0.0000e+00\n",
            "Epoch 392/400\n",
            "80/80 [==============================] - 0s 806us/sample - loss: 4.9485e-04 - acc: 0.0125 - val_loss: 1.8307e-04 - val_acc: 0.0000e+00\n",
            "Epoch 393/400\n",
            "80/80 [==============================] - 0s 806us/sample - loss: 4.9075e-04 - acc: 0.0125 - val_loss: 1.7340e-04 - val_acc: 0.0000e+00\n",
            "Epoch 394/400\n",
            "80/80 [==============================] - 0s 963us/sample - loss: 4.9112e-04 - acc: 0.0125 - val_loss: 1.6716e-04 - val_acc: 0.0000e+00\n",
            "Epoch 395/400\n",
            "80/80 [==============================] - 0s 812us/sample - loss: 4.9075e-04 - acc: 0.0125 - val_loss: 1.6942e-04 - val_acc: 0.0000e+00\n",
            "Epoch 396/400\n",
            "80/80 [==============================] - 0s 748us/sample - loss: 4.8319e-04 - acc: 0.0125 - val_loss: 1.8528e-04 - val_acc: 0.0000e+00\n",
            "Epoch 397/400\n",
            "80/80 [==============================] - 0s 772us/sample - loss: 4.8535e-04 - acc: 0.0125 - val_loss: 1.9032e-04 - val_acc: 0.0000e+00\n",
            "Epoch 398/400\n",
            "80/80 [==============================] - 0s 835us/sample - loss: 4.8201e-04 - acc: 0.0125 - val_loss: 1.7421e-04 - val_acc: 0.0000e+00\n",
            "Epoch 399/400\n",
            "80/80 [==============================] - 0s 831us/sample - loss: 4.7876e-04 - acc: 0.0125 - val_loss: 1.6910e-04 - val_acc: 0.0000e+00\n",
            "Epoch 400/400\n",
            "80/80 [==============================] - 0s 760us/sample - loss: 4.7842e-04 - acc: 0.0125 - val_loss: 1.6923e-04 - val_acc: 0.0000e+00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_JWQVGHDjxz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = model.predict(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpIM4hIwDz0e",
        "colab_type": "code",
        "outputId": "739f0ba6-6b79-4423-f166-83a5ba6a08d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "predictions[:]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.8552242 ],\n",
              "       [0.8877737 ],\n",
              "       [0.36559498],\n",
              "       [0.863587  ],\n",
              "       [0.95191216],\n",
              "       [0.20604378],\n",
              "       [0.39971474],\n",
              "       [0.87180144],\n",
              "       [0.7547141 ],\n",
              "       [0.71521145],\n",
              "       [0.94540846],\n",
              "       [0.43423542],\n",
              "       [0.6227692 ],\n",
              "       [0.5801731 ],\n",
              "       [0.5693538 ],\n",
              "       [0.35438758],\n",
              "       [0.34329   ],\n",
              "       [0.49155733],\n",
              "       [0.83806634],\n",
              "       [0.15298216]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7hK3YoND3JU",
        "colab_type": "code",
        "outputId": "d5fadea8-be22-4426-ae6d-7a63d292da5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "plt.scatter(range(len(y_test)), predictions, c='r')\n",
        "plt.scatter(range(len(y_test)), y_test, c='g')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD4CAYAAADvsV2wAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUOCLiATi/wFj3EFs2Of2tgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewwuQ3FqEM7d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}